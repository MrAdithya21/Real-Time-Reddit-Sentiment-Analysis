{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTavG4ij/IDSDoVLbaFErU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrAdithya21/Real-Time-Reddit-Sentiment-Analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment Refinement Using NLP Models (VADER & BERT)"
      ],
      "metadata": {
        "id": "t9fXDNVdUBRW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I28M1MWVT9Ml"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize VADER Sentiment Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Initialize BERT Sentiment Classifier\n",
        "bert_sentiment = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    vader_score = sia.polarity_scores(text)[\"compound\"]\n",
        "    vader_label = \"positive\" if vader_score > 0.05 else \"negative\" if vader_score < -0.05 else \"neutral\"\n",
        "\n",
        "    bert_result = bert_sentiment(text)[0][\"label\"]\n",
        "    bert_label = \"positive\" if \"5\" in bert_result or \"4\" in bert_result else \"negative\" if \"1\" in bert_result else \"neutral\"\n",
        "\n",
        "    return vader_label, bert_label\n",
        "\n",
        "# Sample DataFrame (Replace this with your actual DataFrame)\n",
        "# df = pd.read_csv(\"your_data.csv\")  # Uncomment this if you have a CSV file\n",
        "\n",
        "# Apply sentiment analysis\n",
        "df[\"VADER_sentiment\"], df[\"BERT_sentiment\"] = zip(*df[\"text\"].apply(analyze_sentiment))\n",
        "\n",
        "# Display refined sentiment analysis results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count sentiment occurrences\n",
        "sentiment_counts = df[\"BERT_sentiment\"].value_counts()\n",
        "\n",
        "# Plot Sentiment Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sentiment_counts.plot(kind=\"bar\", color=[\"red\", \"blue\", \"green\"])\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Sentiment Analysis using VADER & BERT\")\n",
        "plt.show()\n",
        "\n",
        "# Display DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition (NER) for Trending Topics"
      ],
      "metadata": {
        "id": "I-68M4WtUHYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy"
      ],
      "metadata": {
        "id": "xoMmFBCJUIpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract entities\n",
        "def extract_named_entities(text):\n",
        "    doc = nlp(text)\n",
        "    return [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"GPE\", \"PERSON\"]]  # ORG = Organizations, GPE = Locations\n",
        "\n",
        "# Apply entity recognition\n",
        "df[\"entities\"] = df[\"text\"].apply(extract_named_entities)\n",
        "\n",
        "# Get top trending topics\n",
        "entity_list = [entity for entities in df[\"entities\"] for entity in entities]\n",
        "top_entities = Counter(entity_list).most_common(10)\n",
        "\n",
        "print(\"Top 10 Trending Topics:\", top_entities)"
      ],
      "metadata": {
        "id": "y0z0m6KBULkx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}